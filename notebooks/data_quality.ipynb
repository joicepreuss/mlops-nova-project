{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Dict, Tuple, Any\n",
    "import great_expectations as ge\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)    \n",
    "\n",
    "# CODE FOR DATA FEATURE ENGINEERING EXPECTATIONS\n",
    "def check_data_feature_engineering(df: pd.DataFrame, parameters : Dict[str, Any]) -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Check expectations for the feature engineered dataset.\n",
    "    - Check if the numerical features are in the expected range.\n",
    "    - Check if the onehotencoded categorical features have values 0 or 1.\n",
    "\n",
    "    Afterwards save the validation results and raise an exception and save the errors, if any of the expectations fail.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        df (pd.DataFrame): Dataframe to check for nulls.\n",
    "        parameters (Dict): Parameters from the configuration file.\n",
    "\n",
    "    Returns:\n",
    "    --\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy().drop(columns=['y_pred'])\n",
    "\n",
    "    folder_path = '../data/08_reporting/Expectations_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    ohencoded_values = [0,1]\n",
    "    ranges = parameters[\"num_quality_ranges\"]\n",
    "\n",
    "    gdf = ge.from_pandas(df)\n",
    "    for column in num_cols:\n",
    "        gdf.expect_column_values_to_be_between(column,ranges['min'],ranges['max'])\n",
    "\n",
    "    for column in cat_cols:\n",
    "        gdf.expect_column_values_to_be_in_set(column, ohencoded_values)\n",
    "\n",
    "    # Create the validation results and save them in a json file.\n",
    "    validation_results = gdf.validate()\n",
    "    file_path_validation_results = os.path.join(folder_path, \"feature_engineered_data_validation_results.json\")\n",
    "    with open(file_path_validation_results, 'w') as json_file:\n",
    "        json.dump(validation_results.to_json_dict(), json_file)\n",
    "\n",
    "    failed_expectations = [result for result in validation_results[\"results\"] if not result[\"success\"]]\n",
    "    \n",
    "    logger.info(\n",
    "        f\"Total Expectations: {len(validation_results['results'])}\"\n",
    "        f\"Failed Expectations: {len(failed_expectations)}\"\n",
    "    )\n",
    "    \n",
    "    # Collects the errors in a list and saves them in a json file.\n",
    "    # Afterwards raises an exception with the errors.\n",
    "    if failed_expectations:\n",
    "        collect_errors = []\n",
    "        for idx, failed_expectation in enumerate(failed_expectations, start=1):\n",
    "            collect_errors.append(\n",
    "                f\"  Failed Expectation {idx}:\"\n",
    "                f\"  Expectation Type: {failed_expectation['expectation_config']['expectation_type']}\"\n",
    "                f\"  Column: {failed_expectation['expectation_config']['kwargs']['column']}\"\n",
    "                f\"  Details: {failed_expectation['result']}\")\n",
    "            \n",
    "            # Saves the collected errors in a json file.\n",
    "            file_path = os.path.join(folder_path, 'feature_engineered_data_errors.json')\n",
    "            with open(file_path, 'w') as json_file:\n",
    "                json.dump(collect_errors, json_file)\n",
    "    \n",
    "        raise Exception(\n",
    "            f\"Data Quality Validation Failed: {collect_errors}\"\n",
    "        )\n",
    "   \n",
    "\n",
    "# CODE FOR DATA CLEANING EXPECTATIONS\n",
    "def check_nulls(gdf, columns):\n",
    "    for column in columns:\n",
    "        gdf.expect_column_values_to_not_be_null(column)\n",
    "\n",
    "def check_categorical_unique_values(gdf, dict_cat_cols):\n",
    "    for column in dict_cat_cols.keys():\n",
    "        gdf.expect_column_values_to_be_in_set(column, dict_cat_cols[column])\n",
    "\n",
    "def check_dtype(gdf, columns, dtype):\n",
    "    if dtype == 'numeric':\n",
    "        for column in columns:\n",
    "            gdf.expect_column_values_to_be_in_type_list(column, ['int64', 'float64'])\n",
    "    else:\n",
    "        for column in columns:\n",
    "            gdf.expect_column_values_to_be_in_type_list(column, [\"str\"])\n",
    "\n",
    "def check_if_column_exist(gdf, column_list):\n",
    "    for column in column_list:\n",
    "        gdf.expect_column_to_exist(column)\n",
    "\n",
    "def check_data_cleaning(df: pd.DataFrame, parameters : Dict[str, Any]) -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Check expectations for the cleaned dataset.\n",
    "    - Check if the number of columns.\n",
    "    - Check if the columns exist.\n",
    "    - Check if the columns are of the correct type.\n",
    "    - Check if the categorical columns have the correct unique values.\n",
    "    - Check if the numeric columns are within the correct range.\n",
    "    - Check if the columns have null values.\n",
    "    - Check if the ID has only unique values.\n",
    "    - Check if the median of the SalePrice is within the threshold.\n",
    "    - Check if the YearBuilt and YrSold are within the correct range.\n",
    "\n",
    "    Afterwards save the validation results and raise an exception and save the errors, if any of the expectations fail.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        df (pd.DataFrame): Dataframe to check for nulls.\n",
    "        parameters (Dict): Parameters from the configuration file.\n",
    "\n",
    "    Returns:\n",
    "    --\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creates a folder to save the expectations results.\n",
    "    folder_path = '../data/08_reporting/Expectations_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    current_year = datetime.date.today().year + 1\n",
    "    num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    num_columns = parameters[\"num_columns\"]\n",
    "    column_list = parameters[\"column_list\"]\n",
    "    cat_unique_values = parameters[\"categorical_unique_values\"]\n",
    "    median_sales_price = parameters[\"median_sales_price\"]\n",
    "    median_threshold = parameters[\"median_threshold\"]\n",
    "\n",
    "    ranges = parameters[\"num_quality_ranges\"]\n",
    "    gdf = ge.from_pandas(df)\n",
    "\n",
    "    gdf.expect_table_column_count_to_equal(num_columns)\n",
    "    check_if_column_exist(gdf, column_list)\n",
    "    check_dtype(gdf, num_cols, dtype='numeric')\n",
    "    check_dtype(gdf, cat_cols, dtype='object')\n",
    "    check_categorical_unique_values(gdf, cat_unique_values)\n",
    "    \n",
    "    gdf.expect_column_median_to_be_between(\"SalePrice\", \n",
    "                                           median_sales_price*(1-median_threshold), \n",
    "                                           median_sales_price*(1+median_threshold))\n",
    "    check_nulls(gdf, gdf.columns)\n",
    "    gdf.expect_column_values_to_be_unique(\"Id\")\n",
    "    gdf.expect_column_max_to_be_between(\"YearBuilt\", 1800, current_year)\n",
    "    gdf.expect_column_max_to_be_between(\"YrSold\", 1950, current_year)\n",
    "    \n",
    "    # Create the validation results and save them in a json file.\n",
    "    validation_results = gdf.validate()\n",
    "    file_path_validation_results = os.path.join(folder_path, \"Cleaned_data_validation_results.json\")\n",
    "    validation_results.to_json_dict(file_path_validation_results)\n",
    "\n",
    "    failed_expectations = [result for result in validation_results[\"results\"] if not result[\"success\"]]\n",
    "    \n",
    "    logger.info(\n",
    "        f\"Total Expectations: {len(validation_results['results'])}\"\n",
    "        f\"Failed Expectations: {len(failed_expectations)}\"\n",
    "    )\n",
    "    \n",
    "    # Collects the errors in a list and saves them in a json file.\n",
    "    # Afterwards raises an exception with the errors.\n",
    "    if failed_expectations:\n",
    "        collect_errors = []\n",
    "        for idx, failed_expectation in enumerate(failed_expectations, start=1):\n",
    "            collect_errors.append(\n",
    "                f\"  Failed Expectation {idx}:\"\n",
    "                f\"  Expectation Type: {failed_expectation['expectation_config']['expectation_type']}\"\n",
    "                f\"  Column: {failed_expectation['expectation_config']['kwargs']['column']}\"\n",
    "                f\"  Details: {failed_expectation['result']}\")\n",
    "            \n",
    "            # Saves the collected errors in a json file.\n",
    "            file_path = os.path.join(folder_path, 'Cleaned_data_errors.json')\n",
    "            with open(file_path, 'w') as json_file:\n",
    "                json.dump(collect_errors, json_file)\n",
    "    \n",
    "        raise Exception(\n",
    "            f\"Data Quality Validation Failed: {collect_errors}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file from C:\\Users\\jkick\\Documents\\OFFLINE\\mlops-nova-project\\data\\02_intermediate\\X_train_cleaned.csv\n",
    "df = pd.read_csv('../data/02_intermediate/X_train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical__MSSubClass\n",
      "numerical__LotFrontage\n",
      "numerical__LotArea\n",
      "numerical__OverallQual\n",
      "numerical__OverallCond\n",
      "numerical__YearBuilt\n",
      "numerical__YearRemodAdd\n",
      "numerical__MasVnrArea\n",
      "numerical__BsmtFinSF1\n",
      "numerical__BsmtFinSF2\n",
      "numerical__BsmtUnfSF\n",
      "numerical__TotalBsmtSF\n",
      "numerical__1stFlrSF\n",
      "numerical__2ndFlrSF\n",
      "numerical__LowQualFinSF\n",
      "numerical__GrLivArea\n",
      "numerical__BsmtFullBath\n",
      "numerical__BsmtHalfBath\n",
      "numerical__FullBath\n",
      "numerical__HalfBath\n",
      "numerical__BedroomAbvGr\n",
      "numerical__KitchenAbvGr\n",
      "numerical__TotRmsAbvGrd\n",
      "numerical__Fireplaces\n",
      "numerical__GarageYrBlt\n",
      "numerical__GarageCars\n",
      "numerical__GarageArea\n",
      "numerical__WoodDeckSF\n",
      "numerical__OpenPorchSF\n",
      "numerical__EnclosedPorch\n",
      "numerical__3SsnPorch\n",
      "numerical__ScreenPorch\n",
      "numerical__MoSold\n",
      "numerical__YrSold\n"
     ]
    }
   ],
   "source": [
    "# print every column name with numercial_\n",
    "for col in df.columns:\n",
    "    if col.startswith('numerical_'):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical__MSZoning\n",
      "categorical__Street\n",
      "categorical__LotShape\n",
      "categorical__LandContour\n",
      "categorical__Utilities\n",
      "categorical__LotConfig\n",
      "categorical__LandSlope\n",
      "categorical__Neighborhood\n",
      "categorical__Condition1\n",
      "categorical__Condition2\n",
      "categorical__BldgType\n",
      "categorical__HouseStyle\n",
      "categorical__RoofStyle\n",
      "categorical__RoofMatl\n",
      "categorical__Exterior1st\n",
      "categorical__Exterior2nd\n",
      "categorical__MasVnrType\n",
      "categorical__ExterQual\n",
      "categorical__ExterCond\n",
      "categorical__Foundation\n",
      "categorical__BsmtQual\n",
      "categorical__BsmtCond\n",
      "categorical__BsmtExposure\n",
      "categorical__BsmtFinType1\n",
      "categorical__BsmtFinType2\n",
      "categorical__Heating\n",
      "categorical__HeatingQC\n",
      "categorical__CentralAir\n",
      "categorical__Electrical\n",
      "categorical__KitchenQual\n",
      "categorical__Functional\n",
      "categorical__GarageType\n",
      "categorical__GarageFinish\n",
      "categorical__GarageQual\n",
      "categorical__GarageCond\n",
      "categorical__PavedDrive\n",
      "categorical__SaleType\n",
      "categorical__SaleCondition\n"
     ]
    }
   ],
   "source": [
    "# print every column name with numercial_\n",
    "for col in df.columns:\n",
    "    if col.startswith('categorical_'):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_cleaning(df, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housepricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
