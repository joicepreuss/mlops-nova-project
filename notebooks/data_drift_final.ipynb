{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Tuple, Any, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nannyml as nml\n",
    "from nannyml.drift.multivariate.data_reconstruction.result import Result\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_data_drift(reference : pd.DataFrame, analysis : pd.DataFrame, parameters : Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Data drift detection.\n",
    "    - Multivariate data drift\n",
    "    - Univariate data drift\n",
    "    - Model performance drift\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        parameters (Dict[str, Any]): Parameters\n",
    "\n",
    "    \"\"\"\n",
    "    reference = create_timestamp_column(reference, \n",
    "                                        column_name_year=\"YrSold\", \n",
    "                                        column_name_month=\"MoSold\")\n",
    "    \n",
    "    analysis = create_timestamp_column(analysis, \n",
    "                                       column_name_year=\"YrSold\", \n",
    "                                       column_name_month=\"MoSold\")\n",
    "    \n",
    "    feature_columns = parameters[\"most_important_features\"]\n",
    "\n",
    "    reference = reference[feature_columns + [\"timestamp\", \"y_pred\", \"y_true\"]]\n",
    "    analysis = analysis[feature_columns + [\"timestamp\", \"y_pred\"]]\n",
    "    \n",
    "    calculate_drift_multivariat(reference, \n",
    "                                 analysis, \n",
    "                                 feature_column_names=feature_columns,\n",
    "                                 timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    calculate_drift_univariate(reference, \n",
    "                                analysis, \n",
    "                                column_names=feature_columns, \n",
    "                                treat_as_categorical=[], \n",
    "                                timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    estimate_performance(reference,\n",
    "                        analysis,\n",
    "                        feature_column_names=feature_columns,\n",
    "                        y_pred=\"y_pred\",\n",
    "                        y_true=\"y_true\",\n",
    "                        timestamp_column_name=\"timestamp\",\n",
    "                        metrics=['rmse', 'rmsle'],\n",
    "                        tune_hyperparameters=False)\n",
    "    \n",
    "    create_psi_plot(feature_columns, reference, analysis)\n",
    "\n",
    "\n",
    "\n",
    "def create_timestamp_column(df : pd.DataFrame, column_name_year : str, column_name_month : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function creates a new timestamp column using a passed year and month column.\n",
    "    \"\"\"\n",
    "    df['timestamp'] = pd.to_datetime(df[column_name_year].astype(str) + '-' + df[column_name_month].astype(str), format='%Y-%m')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_drift_multivariat(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                 feature_column_names : List[str], timestamp_column_name : str=\"timestamp\") -> None:\n",
    "    \"\"\"\n",
    "    Calculates and plots the multivariant data drift.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Multivariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.DataReconstructionDriftCalculator(column_names=feature_column_names,\n",
    "                                                 timestamp_column_name=timestamp_column_name\n",
    "                                                 )\n",
    "    calc.fit(reference)\n",
    "\n",
    "    results = calc.calculate(analysis)\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Multivariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Multivariate_reference_results.csv'))\n",
    "\n",
    "    figure = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'multivariate_drift.html')\n",
    "    figure.write_html(file_path)\n",
    "\n",
    "\n",
    "def calculate_drift_univariate(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                column_names : List[str], treat_as_categorical : List[str],\n",
    "                                timestamp_column_name : str, continuous_methods : List[str]=['kolmogorov_smirnov', 'jensen_shannon'],\n",
    "                                categorical_methods : List[str]=['chi2', 'jensen_shannon']) -> Result:\n",
    "    \"\"\"\n",
    "    Calculates and plots the univariate data drift.\n",
    "    The used methods are:\n",
    "    - Continuous: Kolmogorov-Smirnov, Jensen-Shannon\n",
    "    - Categorical: Chi2, Jensen-Shannon\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        column_names (List[str]): List of column names\n",
    "        treat_as_categorical (List[str]): List of column names to treat as categorical\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        continuous_methods (List[str]): List of continuous methods\n",
    "        categorical_methods (List[str]): List of categorical methods\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Univariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.UnivariateDriftCalculator(column_names=column_names,\n",
    "                                         treat_as_categorical=treat_as_categorical,\n",
    "                                         timestamp_column_name=timestamp_column_name,\n",
    "                                         continuous_methods=continuous_methods,\n",
    "                                         categorical_methods=categorical_methods\n",
    "                                         )\n",
    "    calc.fit(reference)\n",
    "    results = calc.calculate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Univariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Univariate_reference_results.csv'))\n",
    "\n",
    "    jensen = results.filter(column_names=results.continuous_column_names, methods=['jensen_shannon']).plot(kind='drift')\n",
    "    file_path_jensen = os.path.join(folder_path, 'Univariate_drift_jensen_shannon.html')\n",
    "    jensen.write_html(file_path_jensen)\n",
    "    \n",
    "    kolgomorov = results.filter(column_names=results.continuous_column_names, methods=['kolmogorov_smirnov']).plot(kind='drift')\n",
    "    file_path_kolgomorov = os.path.join(folder_path, 'Univariate_drift_kolgomorov_smirnov.html')\n",
    "    kolgomorov.write_html(file_path_kolgomorov)\n",
    "\n",
    "\n",
    "\n",
    "def estimate_performance(reference : pd.DataFrame, \n",
    "                         analysis : pd.DataFrame,\n",
    "                         feature_column_names : List[str], \n",
    "                         y_pred : pd.Series, y_true : pd.Series,\n",
    "                         timestamp_column_name : str, \n",
    "                         metrics : str =\"mse\",\n",
    "                         tune_hyperparameters = False): \n",
    "    \"\"\"\n",
    "    Estimates the model performance using the DLE algorithm from NannyML.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        y_pred (pd.Series): Predicted target values\n",
    "        y_true (pd.Series): True target values\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        metrics (str): Metric to use for performance estimation\n",
    "        tune_hyperparameters (bool): Whether to tune the hyperparameters\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Estimate_performance'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    estimator = nml.DLE(feature_column_names=feature_column_names,\n",
    "                        y_pred=y_pred,\n",
    "                        y_true=y_true,\n",
    "                        timestamp_column_name=timestamp_column_name,\n",
    "                        metrics=metrics,\n",
    "                        tune_hyperparameters=tune_hyperparameters\n",
    "                        )\n",
    "    \n",
    "    estimator.fit(reference)\n",
    "    results = estimator.estimate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Estimate_performance_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Estimate_performance_reference_results.csv'))\n",
    "\n",
    "    metric_fig = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'estimate_performance.html')\n",
    "    metric_fig.write_html(file_path)\n",
    "\n",
    "\n",
    "# CODE FOR PSI FROM LAB1\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''\n",
    "    Code copied from the Practical Lab for data drift from MLOps course.\n",
    "    Calculate the PSI (population stability index) across all variables.\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "def create_psi_plot(numerical_features, reference, analysis):\n",
    "    \"\"\"\n",
    "    Create a plot of the PSI values for each numerical feature\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    psis_num = []\n",
    "\n",
    "    #Using the github implementation to compute PSI's numerical features\n",
    "    for feature_name in numerical_features:\n",
    "        psi = calculate_psi(reference[feature_name], analysis[feature_name], buckettype='bins', buckets=20, axis=0)\n",
    "        psis_num.append(psi)\n",
    "    #Plot each feature's PSI value\n",
    "    height = psis_num\n",
    "    bars = numerical_features\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.barh(y_pos, height)\n",
    "    plt.axvline(x=0.2,color='red')\n",
    "    plt.yticks(y_pos, bars)\n",
    "    plt.xlabel(\"PSI\")\n",
    "    plt.title(\"PSI for numerical features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    file_path = os.path.join(folder_path, 'psi_numerical_features.png')\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"most_important_features\": [\"OverallQual\", \"GrLivArea\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load analysis and reference file from data/09_data_drift_test\n",
    "reference = pd.read_csv('../data/09_data_drift_test/reference.csv')\n",
    "analysis = pd.read_csv('../data/09_data_drift_test/analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:299: FutureWarning:\n",
      "\n",
      "The behavior of indexing on a MultiIndex with a nested sequence of labels is deprecated and will change in a future version. `series.loc[label, sequence]` will raise if any members of 'sequence' or not present in the index's second level. To retain the old behavior, use `series.index.isin(sequence, level=1)`\n",
      "\n",
      "c:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "c:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     OverallQual  GrLivArea  timestamp         y_pred\n",
      "0              6       1068 2006-02-01  137533.376869\n",
      "1              8       4000 2010-04-01  298351.239230\n",
      "2              5       4000 2010-03-01  125230.692480\n",
      "3              6       1664 2006-10-01  150395.898606\n",
      "4              9       4000 2009-09-01  300085.203762\n",
      "..           ...        ...        ...            ...\n",
      "287            4       1131 2007-03-01  133248.157745\n",
      "288            7       4000 2009-06-01  246826.675290\n",
      "289            7       1456 2008-10-01  192437.386131\n",
      "290            4       4000 2009-10-01  138356.199480\n",
      "291            4        864 2009-07-01  126708.713828\n",
      "\n",
      "[292 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkick\\AppData\\Local\\Temp\\ipykernel_11860\\1973054359.py:259: DeprecationWarning:\n",
      "\n",
      "Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_drift(reference, analysis, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housepricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
