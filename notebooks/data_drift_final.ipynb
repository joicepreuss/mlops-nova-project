{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Tuple, Any, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nannyml as nml\n",
    "from nannyml.drift.multivariate.data_reconstruction.result import Result\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_data_drift(reference : pd.DataFrame, analysis : pd.DataFrame, parameters : Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Data drift detection.\n",
    "    - Multivariate data drift\n",
    "    - Univariate data drift\n",
    "    - Model performance drift\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        parameters (Dict[str, Any]): Parameters\n",
    "\n",
    "    \"\"\"\n",
    "    reference = create_timestamp_column(reference, \n",
    "                                        column_name_year=\"YrSold\", \n",
    "                                        column_name_month=\"MoSold\")\n",
    "    \n",
    "    analysis = create_timestamp_column(analysis, \n",
    "                                       column_name_year=\"YrSold\", \n",
    "                                       column_name_month=\"MoSold\")\n",
    "    \n",
    "    feature_columns = parameters[\"most_important_features\"]\n",
    "\n",
    "    reference = reference[feature_columns + [\"timestamp\", \"y_pred\", \"y_true\"]]\n",
    "    analysis = analysis[feature_columns + [\"timestamp\", \"y_pred\"]]\n",
    "    \n",
    "    multivariat_drift_detected = calculate_drift_multivariat(reference, \n",
    "                                                            analysis, \n",
    "                                                            feature_column_names=feature_columns,\n",
    "                                                            timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    univariat_drift_detected = calculate_drift_univariate(reference, \n",
    "                                                        analysis, \n",
    "                                                        column_names=feature_columns, \n",
    "                                                        treat_as_categorical=[], \n",
    "                                                        timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    estimate_performance(reference,\n",
    "                        analysis,\n",
    "                        feature_column_names=feature_columns,\n",
    "                        y_pred=\"y_pred\",\n",
    "                        y_true=\"y_true\",\n",
    "                        timestamp_column_name=\"timestamp\",\n",
    "                        metrics=['rmse', 'rmsle'],\n",
    "                        tune_hyperparameters=False)\n",
    "    \n",
    "    create_psi_plot(feature_columns, reference, analysis)\n",
    "\n",
    "\n",
    "\n",
    "def create_timestamp_column(df : pd.DataFrame, column_name_year : str, column_name_month : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function creates a new timestamp column using a passed year and month column.\n",
    "    \"\"\"\n",
    "    df['timestamp'] = pd.to_datetime(df[column_name_year].astype(str) + '-' + df[column_name_month].astype(str), format='%Y-%m')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_drift_multivariat(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                 feature_column_names : List[str], timestamp_column_name : str=\"timestamp\") -> None:\n",
    "    \"\"\"\n",
    "    Calculates and plots the multivariant data drift.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Multivariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.DataReconstructionDriftCalculator(column_names=feature_column_names,\n",
    "                                                 timestamp_column_name=timestamp_column_name\n",
    "                                                 )\n",
    "    calc.fit(reference)\n",
    "\n",
    "    results = calc.calculate(analysis)\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Multivariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Multivariate_reference_results.csv'))\n",
    "\n",
    "    figure = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'multivariate_drift.html')\n",
    "    figure.write_html(file_path)\n",
    "\n",
    "    if analysis_results[('reconstruction_error','alert')].max():\n",
    "        logger.info('Multivariate drift detected')\n",
    "        drift_detected = True\n",
    "\n",
    "    return drift_detected\n",
    "\n",
    "\n",
    "def calculate_drift_univariate(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                column_names : List[str], treat_as_categorical : List[str],\n",
    "                                timestamp_column_name : str, continuous_methods : List[str]=['kolmogorov_smirnov', 'jensen_shannon'],\n",
    "                                categorical_methods : List[str]=['chi2', 'jensen_shannon']) -> Result:\n",
    "    \"\"\"\n",
    "    Calculates and plots the univariate data drift.\n",
    "    The used methods are:\n",
    "    - Continuous: Kolmogorov-Smirnov, Jensen-Shannon\n",
    "    - Categorical: Chi2, Jensen-Shannon\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        column_names (List[str]): List of column names\n",
    "        treat_as_categorical (List[str]): List of column names to treat as categorical\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        continuous_methods (List[str]): List of continuous methods\n",
    "        categorical_methods (List[str]): List of categorical methods\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Univariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.UnivariateDriftCalculator(column_names=column_names,\n",
    "                                         treat_as_categorical=treat_as_categorical,\n",
    "                                         timestamp_column_name=timestamp_column_name,\n",
    "                                         continuous_methods=continuous_methods,\n",
    "                                         categorical_methods=categorical_methods\n",
    "                                         )\n",
    "    calc.fit(reference)\n",
    "    results = calc.calculate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Univariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Univariate_reference_results.csv'))\n",
    "\n",
    "    jensen = results.filter(column_names=results.continuous_column_names, methods=['jensen_shannon']).plot(kind='drift')\n",
    "    file_path_jensen = os.path.join(folder_path, 'Univariate_drift_jensen_shannon.html')\n",
    "    jensen.write_html(file_path_jensen)\n",
    "    \n",
    "    kolgomorov = results.filter(column_names=results.continuous_column_names, methods=['kolmogorov_smirnov']).plot(kind='drift')\n",
    "    file_path_kolgomorov = os.path.join(folder_path, 'Univariate_drift_kolgomorov_smirnov.html')\n",
    "    kolgomorov.write_html(file_path_kolgomorov)\n",
    "\n",
    "    drift_dict = {}\n",
    "    drift_kolgomorov = False\n",
    "    drift_jensen = False\n",
    "    for column_name in column_names:\n",
    "        if analysis_results[(column_name,'kolmogorov_smirnov','alert')].max():\n",
    "            logger.info(f'Univariate drift detected - Kolgomorov-Smirnov - {column_name}')\n",
    "            drift_kolgomorov = True\n",
    "        if analysis_results[(column_name,'jensen_shannon','alert')].max():\n",
    "            logger.info(f'Univariate drift detected - Jensen Shannon - {column_name}')\n",
    "            drift_jensen = True\n",
    "        drift_dict[column_name] = {\"kolgomorov\": drift_kolgomorov, \"jensen\": drift_jensen} \n",
    "\n",
    "\n",
    "    return drift_dict\n",
    "\n",
    "def estimate_performance(reference : pd.DataFrame, \n",
    "                         analysis : pd.DataFrame,\n",
    "                         feature_column_names : List[str], \n",
    "                         y_pred : pd.Series, y_true : pd.Series,\n",
    "                         timestamp_column_name : str, \n",
    "                         metrics : str =\"mse\",\n",
    "                         tune_hyperparameters = False): \n",
    "    \"\"\"\n",
    "    Estimates the model performance using the DLE algorithm from NannyML.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        y_pred (pd.Series): Predicted target values\n",
    "        y_true (pd.Series): True target values\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        metrics (str): Metric to use for performance estimation\n",
    "        tune_hyperparameters (bool): Whether to tune the hyperparameters\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Estimate_performance'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    estimator = nml.DLE(feature_column_names=feature_column_names,\n",
    "                        y_pred=y_pred,\n",
    "                        y_true=y_true,\n",
    "                        timestamp_column_name=timestamp_column_name,\n",
    "                        metrics=metrics,\n",
    "                        tune_hyperparameters=tune_hyperparameters\n",
    "                        )\n",
    "    \n",
    "    estimator.fit(reference)\n",
    "    results = estimator.estimate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Estimate_performance_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Estimate_performance_reference_results.csv'))\n",
    "\n",
    "    metric_fig = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'estimate_performance.html')\n",
    "    metric_fig.write_html(file_path)\n",
    "\n",
    "# CODE FOR PSI FROM LAB1\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''\n",
    "    Code copied from the Practical Lab for data drift from MLOps course.\n",
    "    Calculate the PSI (population stability index) across all variables.\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "def create_psi_plot(numerical_features, reference, analysis):\n",
    "    \"\"\"\n",
    "    Create a plot of the PSI values for each numerical feature\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    psis_num = []\n",
    "\n",
    "    #Using the github implementation to compute PSI's numerical features\n",
    "    for feature_name in numerical_features:\n",
    "        psi = calculate_psi(reference[feature_name], analysis[feature_name], buckettype='bins', buckets=20, axis=0)\n",
    "        psis_num.append(psi)\n",
    "    #Plot each feature's PSI value\n",
    "    height = psis_num\n",
    "    bars = numerical_features\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.barh(y_pos, height)\n",
    "    plt.axvline(x=0.2,color='red')\n",
    "    plt.yticks(y_pos, bars)\n",
    "    plt.xlabel(\"PSI\")\n",
    "    plt.title(\"PSI for numerical features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    file_path = os.path.join(folder_path, 'psi_numerical_features.png')\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"most_important_features\": [\"OverallQual\", \"GrLivArea\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load analysis and reference file from data/09_data_drift_test\n",
    "reference = pd.read_csv('../data/09_data_drift_test/reference.csv')\n",
    "analysis = pd.read_csv('../data/09_data_drift_test/analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8414</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>137533.376869</td>\n",
       "      <td>2006-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>98.0</td>\n",
       "      <td>12256</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>298351.239230</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8960</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>125230.692480</td>\n",
       "      <td>2010-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   893          20       RL         70.0     8414   Pave   NaN      Reg   \n",
       "1  1106          60       RL         98.0    12256   Pave   NaN      IR1   \n",
       "2   414          30       RM         56.0     8960   Pave  Grvl      Reg   \n",
       "\n",
       "  LandContour Utilities  ... PoolQC  Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0         Lvl    AllPub  ...    NaN  MnPrv         NaN       0      2   2006   \n",
       "1         Lvl    AllPub  ...    NaN    NaN         NaN       0      4   2010   \n",
       "2         Lvl    AllPub  ...    NaN    NaN         NaN       0      3   2010   \n",
       "\n",
       "  SaleType  SaleCondition         y_pred   timestamp  \n",
       "0       WD         Normal  137533.376869  2006-02-01  \n",
       "1       WD         Normal  298351.239230  2010-04-01  \n",
       "2       WD         Normal  125230.692480  2010-03-01  \n",
       "\n",
       "[3 rows x 82 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:299: FutureWarning:\n",
      "\n",
      "The behavior of indexing on a MultiIndex with a nested sequence of labels is deprecated and will change in a future version. `series.loc[label, sequence]` will raise if any members of 'sequence' or not present in the index's second level. To retain the old behavior, use `series.index.isin(sequence, level=1)`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">chunk</th>\n",
       "      <th colspan=\"6\" halign=\"left\">OverallQual</th>\n",
       "      <th colspan=\"8\" halign=\"left\">GrLivArea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">chunk</th>\n",
       "      <th colspan=\"3\" halign=\"left\">kolmogorov_smirnov</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">jensen_shannon</th>\n",
       "      <th colspan=\"4\" halign=\"left\">kolmogorov_smirnov</th>\n",
       "      <th colspan=\"4\" halign=\"left\">jensen_shannon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>...</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "      <th>value</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "      <th>value</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0:28]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.170761</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.230053</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29:57]</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>2006-07-01</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.096835</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.117029</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.196146</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[58:86]</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>86</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.085262</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.208432</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87:115]</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>115</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.050661</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.334608</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[116:144]</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>144</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.175484</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.264053</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[145:173]</td>\n",
       "      <td>5</td>\n",
       "      <td>145</td>\n",
       "      <td>173</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.090458</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.102622</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[174:202]</td>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>202</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.341403</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.485059</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[203:231]</td>\n",
       "      <td>7</td>\n",
       "      <td>203</td>\n",
       "      <td>231</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.087270</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.909380</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[232:260]</td>\n",
       "      <td>8</td>\n",
       "      <td>232</td>\n",
       "      <td>260</td>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.858644</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.909380</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[261:291]</td>\n",
       "      <td>9</td>\n",
       "      <td>261</td>\n",
       "      <td>291</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>0.144253</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738511</td>\n",
       "      <td>0.23605</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.864104</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk                                                          \\\n",
       "       chunk                                                           \n",
       "         key chunk_index start_index end_index start_date   end_date   \n",
       "0     [0:28]           0           0        28 2006-01-01 2006-06-01   \n",
       "1    [29:57]           1          29        57 2006-07-01 2006-11-01   \n",
       "2    [58:86]           2          58        86 2006-11-01 2007-05-01   \n",
       "3   [87:115]           3          87       115 2007-05-01 2007-08-01   \n",
       "4  [116:144]           4         116       144 2007-08-01 2008-04-01   \n",
       "5  [145:173]           5         145       173 2008-04-01 2008-08-01   \n",
       "6  [174:202]           6         174       202 2008-08-01 2009-05-01   \n",
       "7  [203:231]           7         203       231 2009-05-01 2009-08-01   \n",
       "8  [232:260]           8         232       260 2009-08-01 2010-03-01   \n",
       "9  [261:291]           9         261       291 2010-03-01 2010-07-01   \n",
       "\n",
       "                   OverallQual                                  ...  \\\n",
       "            kolmogorov_smirnov                                  ...   \n",
       "     period              value upper_threshold lower_threshold  ...   \n",
       "0  analysis           0.110888        0.144253            None  ...   \n",
       "1  analysis           0.096835        0.144253            None  ...   \n",
       "2  analysis           0.085262        0.144253            None  ...   \n",
       "3  analysis           0.050661        0.144253            None  ...   \n",
       "4  analysis           0.052787        0.144253            None  ...   \n",
       "5  analysis           0.090458        0.144253            None  ...   \n",
       "6  analysis           0.082900        0.144253            None  ...   \n",
       "7  analysis           0.087270        0.144253            None  ...   \n",
       "8  analysis           0.052787        0.144253            None  ...   \n",
       "9  analysis           0.104949        0.144253            None  ...   \n",
       "\n",
       "                                 GrLivArea                                  \\\n",
       "   jensen_shannon       kolmogorov_smirnov                                   \n",
       "  lower_threshold alert              value upper_threshold lower_threshold   \n",
       "0            None  True           0.170761         0.23605            None   \n",
       "1            None  True           0.117029         0.23605            None   \n",
       "2            None  True           0.100968         0.23605            None   \n",
       "3            None  True           0.129310         0.23605            None   \n",
       "4            None  True           0.175484         0.23605            None   \n",
       "5            None  True           0.102622         0.23605            None   \n",
       "6            None  True           0.341403         0.23605            None   \n",
       "7            None  True           0.858644         0.23605            None   \n",
       "8            None  True           0.858644         0.23605            None   \n",
       "9            None  True           0.738511         0.23605            None   \n",
       "\n",
       "                                                               \n",
       "         jensen_shannon                                        \n",
       "   alert          value upper_threshold lower_threshold alert  \n",
       "0  False       0.230053             0.1            None  True  \n",
       "1  False       0.196146             0.1            None  True  \n",
       "2  False       0.208432             0.1            None  True  \n",
       "3  False       0.334608             0.1            None  True  \n",
       "4  False       0.264053             0.1            None  True  \n",
       "5  False       0.211550             0.1            None  True  \n",
       "6   True       0.485059             0.1            None  True  \n",
       "7   True       0.909380             0.1            None  True  \n",
       "8   True       0.909380             0.1            None  True  \n",
       "9   True       0.864104             0.1            None  True  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkick\\AppData\\Local\\Temp\\ipykernel_11860\\467200210.py:284: DeprecationWarning:\n",
      "\n",
      "Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_drift(reference, analysis, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housepricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
