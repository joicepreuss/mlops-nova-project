{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Tuple, Any, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nannyml as nml\n",
    "from nannyml.drift.multivariate.data_reconstruction.result import Result\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_data_drift(reference : pd.DataFrame, analysis : pd.DataFrame, parameters : Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Data drift detection.\n",
    "    - Multivariate data drift\n",
    "    - Univariate data drift\n",
    "    - Model performance drift\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        parameters (Dict[str, Any]): Parameters\n",
    "\n",
    "    \"\"\"\n",
    "    reference = create_timestamp_column(reference, \n",
    "                                        column_name_year=\"YrSold\", \n",
    "                                        column_name_month=\"MoSold\")\n",
    "    \n",
    "    analysis = create_timestamp_column(analysis, \n",
    "                                       column_name_year=\"YrSold\", \n",
    "                                       column_name_month=\"MoSold\")\n",
    "    \n",
    "    feature_columns = parameters[\"most_important_features\"]\n",
    "\n",
    "    reference = reference[feature_columns + [\"timestamp\"]]\n",
    "    analysis = analysis[feature_columns + [\"timestamp\"]]\n",
    "    \n",
    "    calculate_drift_multivariat(reference, \n",
    "                                 analysis, \n",
    "                                 feature_column_names=feature_columns,\n",
    "                                 timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    calculate_drift_univariate(reference, \n",
    "                                analysis, \n",
    "                                column_names=feature_columns, \n",
    "                                treat_as_categorical=[], \n",
    "                                timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    # estimate_performance(reference,\n",
    "    #                     analysis,\n",
    "    #                     feature_column_names=feature_columns,\n",
    "    #                     y_pred=\"y_pred\",\n",
    "    #                     y_true=\"y_true\",\n",
    "    #                     timestamp_column_name=\"timestamp\",\n",
    "    #                     metrics=['rmse', 'rmsle'],\n",
    "    #                     tune_hyperparameters=False)\n",
    "    \n",
    "    create_psi_plot(feature_columns, reference, analysis)\n",
    "\n",
    "\n",
    "\n",
    "def create_timestamp_column(df : pd.DataFrame, column_name_year : str, column_name_month : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function creates a new timestamp column using a passed year and month column.\n",
    "    \"\"\"\n",
    "    df['timestamp'] = pd.to_datetime(df[column_name_year].astype(str) + '-' + df[column_name_month].astype(str), format='%Y-%m')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_drift_multivariat(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                 feature_column_names : List[str], timestamp_column_name : str=\"timestamp\") -> None:\n",
    "    \"\"\"\n",
    "    Calculates and plots the multivariant data drift.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Multivariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.DataReconstructionDriftCalculator(column_names=feature_column_names,\n",
    "                                                 timestamp_column_name=timestamp_column_name\n",
    "                                                 )\n",
    "    calc.fit(reference)\n",
    "\n",
    "    results = calc.calculate(analysis)\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Multivariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Multivariate_reference_results.csv'))\n",
    "\n",
    "    figure = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'multivariate_drift.html')\n",
    "    figure.write_html(file_path)\n",
    "\n",
    "\n",
    "def calculate_drift_univariate(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                column_names : List[str], treat_as_categorical : List[str],\n",
    "                                timestamp_column_name : str, continuous_methods : List[str]=['kolmogorov_smirnov', 'jensen_shannon'],\n",
    "                                categorical_methods : List[str]=['chi2', 'jensen_shannon']) -> Result:\n",
    "    \"\"\"\n",
    "    Calculates and plots the univariate data drift.\n",
    "    The used methods are:\n",
    "    - Continuous: Kolmogorov-Smirnov, Jensen-Shannon\n",
    "    - Categorical: Chi2, Jensen-Shannon\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        column_names (List[str]): List of column names\n",
    "        treat_as_categorical (List[str]): List of column names to treat as categorical\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        continuous_methods (List[str]): List of continuous methods\n",
    "        categorical_methods (List[str]): List of categorical methods\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Univariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.UnivariateDriftCalculator(column_names=column_names,\n",
    "                                         treat_as_categorical=treat_as_categorical,\n",
    "                                         timestamp_column_name=timestamp_column_name,\n",
    "                                         continuous_methods=continuous_methods,\n",
    "                                         categorical_methods=categorical_methods\n",
    "                                         )\n",
    "    calc.fit(reference)\n",
    "    results = calc.calculate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Univariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Univariate_reference_results.csv'))\n",
    "\n",
    "    jensen = results.filter(column_names=results.continuous_column_names, methods=['jensen_shannon']).plot(kind='drift')\n",
    "    file_path_jensen = os.path.join(folder_path, 'Univariate_drift_jensen_shannon.html')\n",
    "    jensen.write_html(file_path_jensen)\n",
    "    \n",
    "    kolgomorov = results.filter(column_names=results.continuous_column_names, methods=['kolmogorov_smirnov']).plot(kind='drift')\n",
    "    file_path_kolgomorov = os.path.join(folder_path, 'Univariate_drift_kolgomorov_smirnov.html')\n",
    "    kolgomorov.write_html(file_path_kolgomorov)\n",
    "\n",
    "\n",
    "\n",
    "def estimate_performance(reference : pd.DataFrame, \n",
    "                         analysis : pd.DataFrame,\n",
    "                         feature_column_names : List[str], \n",
    "                         y_pred : pd.Series, y_true : pd.Series,\n",
    "                         timestamp_column_name : str, \n",
    "                         metrics : str =\"mse\",\n",
    "                         tune_hyperparameters = False): \n",
    "    \"\"\"\n",
    "    Estimates the model performance using the DLE algorithm from NannyML.\n",
    "\n",
    "    Args:\n",
    "    --\n",
    "        reference (pd.DataFrame): Reference dataset\n",
    "        analysis (pd.DataFrame): Analysis dataset\n",
    "        feature_column_names (List[str]): List of feature column names\n",
    "        y_pred (pd.Series): Predicted target values\n",
    "        y_true (pd.Series): True target values\n",
    "        timestamp_column_name (str): Timestamp column name\n",
    "        metrics (str): Metric to use for performance estimation\n",
    "        tune_hyperparameters (bool): Whether to tune the hyperparameters\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Estimate_performance'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    estimator = nml.DLE(feature_column_names=feature_column_names,\n",
    "                        y_pred=y_pred,\n",
    "                        y_true=y_true,\n",
    "                        timestamp_column_name=timestamp_column_name,\n",
    "                        metrics=metrics,\n",
    "                        tune_hyperparameters=tune_hyperparameters\n",
    "                        )\n",
    "    \n",
    "    estimator.fit(reference)\n",
    "    results = estimator.estimate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Estimate_performance_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Estimate_performance_reference_results.csv'))\n",
    "\n",
    "    metric_fig = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'estimate_performance.html')\n",
    "    metric_fig.write_html(file_path)\n",
    "\n",
    "\n",
    "# CODE FOR PSI FROM LAB1\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''\n",
    "    Code copied from the Practical Lab for data drift from MLOps course.\n",
    "    Calculate the PSI (population stability index) across all variables.\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "def create_psi_plot(numerical_features, reference, analysis):\n",
    "    \"\"\"\n",
    "    Create a plot of the PSI values for each numerical feature\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    psis_num = []\n",
    "\n",
    "    #Using the github implementation to compute PSI's numerical features\n",
    "    for feature_name in numerical_features:\n",
    "        psi = calculate_psi(reference[feature_name], analysis[feature_name], buckettype='bins', buckets=20, axis=0)\n",
    "        psis_num.append(psi)\n",
    "    #Plot each feature's PSI value\n",
    "    height = psis_num\n",
    "    bars = numerical_features\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.barh(y_pos, height)\n",
    "    plt.axvline(x=0.2,color='red')\n",
    "    plt.yticks(y_pos, bars)\n",
    "    plt.xlabel(\"PSI\")\n",
    "    plt.title(\"PSI for numerical features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    file_path = os.path.join(folder_path, 'psi_numerical_features.png')\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"most_important_features\": [\"OverallQual\", \"GrLivArea\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv('../data/01_raw/house-pricing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load analysis and reference file from data/09_data_drift_test\n",
    "# reference = pd.read_csv('../data/09_data_drift_test/reference.csv')\n",
    "analysis = pd.read_csv('../data/03_primary/X_to_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaime.kuei/Documents/study-repositories/master/second-semester/mlops/project/mlops-nova-project/.mlops-env/lib/python3.9/site-packages/nannyml/base.py:299: FutureWarning:\n",
      "\n",
      "The behavior of indexing on a MultiIndex with a nested sequence of labels is deprecated and will change in a future version. `series.loc[label, sequence]` will raise if any members of 'sequence' or not present in the index's second level. To retain the old behavior, use `series.index.isin(sequence, level=1)`\n",
      "\n",
      "/var/folders/1c/4trmvmbs6h38d0yjvlcf_cqmv3kl5x/T/ipykernel_21665/3573987301.py:258: DeprecationWarning:\n",
      "\n",
      "Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_data_drift(testing, analysis, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housepricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
