{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Tuple, Any, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nannyml as nml\n",
    "from nannyml.drift.multivariate.data_reconstruction.result import Result\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_data_drift(reference : pd.DataFrame, analysis : pd.DataFrame, parameters : Dict[str, Any]):\n",
    "\n",
    "# 1. timestamp column, wird kreiert aus dem month sold and year sold\n",
    "# 2. reference = dataset mit prediction und cleaned und y_true\n",
    "# 3. analysis = mock dataset ohne prediction und cleaned\n",
    "# 4. 2 features distribution verändern\n",
    "# reference dataframe = golden dataset mit test und predictions und y_true (aus raw und predictions)\n",
    "\n",
    "    reference = create_timestamp_column(reference, \n",
    "                                        column_name_year=\"YrSold\", \n",
    "                                        column_name_month=\"MoSold\")\n",
    "    \n",
    "    analysis = create_timestamp_column(analysis, \n",
    "                                       column_name_year=\"YrSold\", \n",
    "                                       column_name_month=\"MoSold\")\n",
    "    \n",
    "    feature_columns = parameters[\"most_important_features\"]\n",
    "\n",
    "    reference = reference[feature_columns + [\"timestamp\", \"y_pred\", \"y_true\"]]\n",
    "    analysis = analysis[feature_columns + [\"timestamp\"]]\n",
    "    \n",
    "    calculate_drift_multivariat(reference, \n",
    "                                 analysis, \n",
    "                                 feature_column_names=feature_columns,\n",
    "                                 timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    calculate_drift_univariate(reference, \n",
    "                                analysis, \n",
    "                                column_names=feature_columns, \n",
    "                                treat_as_categorical=[], \n",
    "                                timestamp_column_name=\"timestamp\")\n",
    "    \n",
    "    estimate_performance(reference,\n",
    "                        analysis,\n",
    "                        feature_column_names=feature_columns,\n",
    "                        y_pred=reference[\"y_pred\"],\n",
    "                        y_true=reference[\"y_true\"],\n",
    "                        timestamp_column_name=\"timestamp\")\n",
    "                        # metrics=['rmse', 'rmsle'],\n",
    "                        # tune_hyperparameters=False)\n",
    "    \n",
    "    create_psi_plot(feature_columns, reference, analysis)\n",
    "\n",
    "\n",
    "\n",
    "def create_timestamp_column(df : pd.DataFrame, column_name_year : str, column_name_month : str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function creates a new timestamp column using a passed year and month column\n",
    "    \"\"\"\n",
    "    df['timestamp'] = pd.to_datetime(df[column_name_year].astype(str) + '-' + df[column_name_month].astype(str), format='%Y-%m')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_drift_multivariat(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                 feature_column_names : List[str], timestamp_column_name : str=\"timestamp\") -> None:\n",
    "    \"\"\"\n",
    "    This function calculates and plots the multivariant data drift\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Multivariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.DataReconstructionDriftCalculator(column_names=feature_column_names,\n",
    "                                                 timestamp_column_name=timestamp_column_name\n",
    "                                                 )\n",
    "    calc.fit(reference)\n",
    "\n",
    "    results = calc.calculate(analysis)\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Multivariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Multivariate_reference_results.csv'))\n",
    "\n",
    "    figure = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'multivariate_drift.html')\n",
    "    figure.write_html(file_path)\n",
    "\n",
    "\n",
    "def calculate_drift_univariate(reference : pd.DataFrame, analysis : pd.DataFrame,\n",
    "                                column_names : List[str], treat_as_categorical : List[str],\n",
    "                                timestamp_column_name : str, continuous_methods : List[str]=['kolmogorov_smirnov', 'jensen_shannon'],\n",
    "                                categorical_methods : List[str]=['chi2', 'jensen_shannon']) -> Result:\n",
    "    \"\"\"\n",
    "    This function calculates and plots the univariate data drift\n",
    "    \"\"\"\n",
    "\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Univariate_drifts'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    calc = nml.UnivariateDriftCalculator(column_names=column_names,\n",
    "                                         treat_as_categorical=treat_as_categorical,\n",
    "                                         timestamp_column_name=timestamp_column_name,\n",
    "                                         continuous_methods=continuous_methods,\n",
    "                                         categorical_methods=categorical_methods\n",
    "                                         )\n",
    "    calc.fit(reference)\n",
    "    results = calc.calculate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Univariate_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Univariate_reference_results.csv'))\n",
    "\n",
    "    jensen = results.filter(column_names=results.continuous_column_names, methods=['jensen_shannon']).plot(kind='drift')\n",
    "    file_path_jensen = os.path.join(folder_path, 'Univariate_drift_jensen_shannon.html')\n",
    "    jensen.write_html(file_path_jensen)\n",
    "    \n",
    "    kolgomorov = results.filter(column_names=results.continuous_column_names, methods=['kolmogorov_smirnov']).plot(kind='drift')\n",
    "    file_path_kolgomorov = os.path.join(folder_path, 'Univariate_drift_kolgomorov_smirnov.html')\n",
    "    kolgomorov.write_html(file_path_kolgomorov)\n",
    "\n",
    "    return results\n",
    "\n",
    "def estimate_performance(reference : pd.DataFrame, \n",
    "                         analysis : pd.DataFrame,\n",
    "                         feature_column_names : List[str], \n",
    "                         y_pred : pd.Series, y_true : pd.Series,\n",
    "                         timestamp_column_name : str, \n",
    "                         metrics : str =\"mse\",):\n",
    "                        #  tune_hyperparameters = False): \n",
    "    \"\"\"\n",
    "    This function is estimating the model performance using the DLE\n",
    "    \"\"\"\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting/Estimate_performance'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    estimator = nml.DLE(feature_column_names=feature_column_names,\n",
    "                        y_pred=y_pred,\n",
    "                        y_true=y_true,\n",
    "                        timestamp_column_name=timestamp_column_name,\n",
    "                        metrics=metrics,\n",
    "                        # tune_hyperparameters=tune_hyperparameters\n",
    "                        )\n",
    "    \n",
    "    estimator.fit(reference)\n",
    "    results = estimator.estimate(analysis)\n",
    "\n",
    "    analysis_results = results.filter(period='analysis').to_df()\n",
    "    reference_results = results.filter(period='reference').to_df()\n",
    "    analysis_results.to_csv(os.path.join(folder_path, 'Estimate_performance_analysis_results.csv'))\n",
    "    reference_results.to_csv(os.path.join(folder_path, 'Estimate_performance_reference_results.csv'))\n",
    "\n",
    "    metric_fig = results.plot()\n",
    "    file_path = os.path.join(folder_path, 'estimate_performance.html')\n",
    "    metric_fig.write_html(file_path)\n",
    "\n",
    "# CODE FOR PSI FROM LAB1\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''Calculate the PSI (population stability index) across all variables\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)\n",
    "\n",
    "def create_psi_plot(numerical_features, reference, analysis):\n",
    "    folder_path = '../data/08_reporting/Data_drifts_reporting'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    psis_num = []\n",
    "\n",
    "    #Using the github implementation to compute PSI's numerical features\n",
    "    for feature_name in numerical_features:\n",
    "        psi = calculate_psi(reference[feature_name], analysis[feature_name], buckettype='bins', buckets=20, axis=0)\n",
    "        psis_num.append(psi)\n",
    "    #Plot each feature's PSI value\n",
    "    height = psis_num\n",
    "    bars = numerical_features\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.barh(y_pos, height)\n",
    "    plt.axvline(x=0.2,color='red')\n",
    "    plt.yticks(y_pos, bars)\n",
    "    plt.xlabel(\"PSI\")\n",
    "    plt.title(\"PSI for numerical features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    file_path = os.path.join(folder_path, 'psi_numerical_features.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "\n",
    "# def calculate_psi_categorical(actual, expected):\n",
    "#     actual_perc = actual.value_counts()/len(actual)\n",
    "#     expected_perc = expected.value_counts()/len(expected)\n",
    "#     actual_classes = list(actual_perc.index) \n",
    "#     expected_classes = list(expected_perc.index)\n",
    "#     PSI = 0\n",
    "#     classes = set(actual_classes + expected_classes)\n",
    "#     for c in classes:\n",
    "#         final_actual_perc = actual_perc[c] if c in actual_classes else 0.00001\n",
    "#         final_expected_perc = expected_perc[c] if c in expected_classes else 0.00001\n",
    "#         PSI += (final_actual_perc - final_expected_perc)*np.log(final_actual_perc/final_expected_perc)\n",
    "#     return PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"most_important_features\": [\"OverallQual\", \"GrLivArea\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = pd.read_csv('../data/03_primary/X_to_predict.csv')\n",
    "y_train = pd.read_csv('../data/05_model_input/y_train.csv')\n",
    "predictions = pd.read_csv('../data/07_model_output/df_with_predict.csv')[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge reference with y_train and predictions on index of reference\n",
    "reference = reference.merge(y_train, left_index=True, right_index=True)\n",
    "reference = reference.merge(predictions, left_index=True, right_index=True)\n",
    "# rename SalePrice to y_true\n",
    "reference = reference.rename(columns={\"SalePrice\": \"y_true\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the reference dataframe, name it analysis and insert some bias in the most important features columns\n",
    "analysis = reference.copy()\n",
    "analysis.loc[analysis[\"OverallQual\"] == 10, \"OverallQual\"] = 9\n",
    "analysis.loc[analysis[\"GrLivArea\"] > 4000, \"GrLivArea\"] = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8414</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>145000</td>\n",
       "      <td>137533.376869</td>\n",
       "      <td>2006-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1106</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>98.0</td>\n",
       "      <td>12256</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>178000</td>\n",
       "      <td>298351.239230</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>414</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8960</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>85000</td>\n",
       "      <td>125230.692480</td>\n",
       "      <td>2010-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>523</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "      <td>150395.898606</td>\n",
       "      <td>2006-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12898</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>127000</td>\n",
       "      <td>300085.203762</td>\n",
       "      <td>2009-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>480</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5925</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Alloca</td>\n",
       "      <td>227000</td>\n",
       "      <td>133248.157745</td>\n",
       "      <td>2007-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1362</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>124.0</td>\n",
       "      <td>16158</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159500</td>\n",
       "      <td>246826.675290</td>\n",
       "      <td>2009-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>803</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8199</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>217000</td>\n",
       "      <td>192437.386131</td>\n",
       "      <td>2008-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>652</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>410000</td>\n",
       "      <td>138356.199480</td>\n",
       "      <td>2009-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>723</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>148000</td>\n",
       "      <td>126708.713828</td>\n",
       "      <td>2009-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0     893          20       RL         70.0     8414   Pave   NaN      Reg   \n",
       "1    1106          60       RL         98.0    12256   Pave   NaN      IR1   \n",
       "2     414          30       RM         56.0     8960   Pave  Grvl      Reg   \n",
       "3     523          50       RM         50.0     5000   Pave   NaN      Reg   \n",
       "4    1037          20       RL         89.0    12898   Pave   NaN      IR1   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "287   480          30       RM         50.0     5925   Pave   NaN      Reg   \n",
       "288  1362          20       RL        124.0    16158   Pave   NaN      IR1   \n",
       "289   803          60       RL         63.0     8199   Pave   NaN      Reg   \n",
       "290   652          70       RL         60.0     9084   Pave   NaN      Reg   \n",
       "291   723          20       RL         70.0     8120   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ...  Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0           Lvl    AllPub  ...  MnPrv         NaN       0      2   2006   \n",
       "1           Lvl    AllPub  ...    NaN         NaN       0      4   2010   \n",
       "2           Lvl    AllPub  ...    NaN         NaN       0      3   2010   \n",
       "3           Lvl    AllPub  ...    NaN         NaN       0     10   2006   \n",
       "4           HLS    AllPub  ...    NaN         NaN       0      9   2009   \n",
       "..          ...       ...  ...    ...         ...     ...    ...    ...   \n",
       "287         Bnk    AllPub  ...  MnPrv         NaN       0      3   2007   \n",
       "288         Low    AllPub  ...    NaN         NaN       0      6   2009   \n",
       "289         Lvl    AllPub  ...    NaN         NaN       0     10   2008   \n",
       "290         Lvl    AllPub  ...  MnPrv         NaN       0     10   2009   \n",
       "291         Lvl    AllPub  ...    NaN         NaN       0      7   2009   \n",
       "\n",
       "    SaleType SaleCondition  y_true         y_pred  timestamp  \n",
       "0         WD        Normal  145000  137533.376869 2006-02-01  \n",
       "1         WD        Normal  178000  298351.239230 2010-04-01  \n",
       "2         WD        Normal   85000  125230.692480 2010-03-01  \n",
       "3         WD        Normal  175000  150395.898606 2006-10-01  \n",
       "4         WD        Normal  127000  300085.203762 2009-09-01  \n",
       "..       ...           ...     ...            ...        ...  \n",
       "287       WD        Alloca  227000  133248.157745 2007-03-01  \n",
       "288       WD        Normal  159500  246826.675290 2009-06-01  \n",
       "289       WD        Normal  217000  192437.386131 2008-10-01  \n",
       "290       WD        Normal  410000  138356.199480 2009-10-01  \n",
       "291       WD        Normal  148000  126708.713828 2009-07-01  \n",
       "\n",
       "[292 rows x 83 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:299: FutureWarning:\n",
      "\n",
      "The behavior of indexing on a MultiIndex with a nested sequence of labels is deprecated and will change in a future version. `series.loc[label, sequence]` will raise if any members of 'sequence' or not present in the index's second level. To retain the old behavior, use `series.index.isin(sequence, level=1)`\n",
      "\n"
     ]
    },
    {
     "ename": "CalculatorException",
     "evalue": "failed while fitting DLE[tune_hyperparameters=False, metrics=['MSE']].\nThe truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:208\u001b[0m, in \u001b[0;36mlog_usage.<locals>.logging_decorator.<locals>.logging_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[39m# log the event\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     logger\u001b[39m.\u001b[39;49mlog(usage_event, md)\n\u001b[0;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:102\u001b[0m, in \u001b[0;36mUsageLogger.log\u001b[1;34m(self, usage_event, metadata)\u001b[0m\n\u001b[0;32m    101\u001b[0m     metadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log(usage_event, metadata)\n\u001b[0;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogged usage for event \u001b[39m\u001b[39m{\u001b[39;00musage_event\u001b[39m}\u001b[39;00m\u001b[39m with metadata \u001b[39m\u001b[39m{\u001b[39;00mmetadata\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:132\u001b[0m, in \u001b[0;36mSegmentUsageTracker._log\u001b[1;34m(self, usage_event, metadata)\u001b[0m\n\u001b[0;32m    131\u001b[0m user_id \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39mUUID(\u001b[39mint\u001b[39m\u001b[39m=\u001b[39muuid\u001b[39m.\u001b[39mgetnode()))\n\u001b[1;32m--> 132\u001b[0m metadata\u001b[39m.\u001b[39mupdate(_get_system_information())\n\u001b[0;32m    133\u001b[0m segment_analytics\u001b[39m.\u001b[39mtrack(user_id, usage_event\u001b[39m.\u001b[39mvalue, metadata)\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:223\u001b[0m, in \u001b[0;36m_get_system_information\u001b[1;34m()\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_system_information\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m    221\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    222\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mos_type\u001b[39m\u001b[39m\"\u001b[39m: platform\u001b[39m.\u001b[39msystem(),\n\u001b[1;32m--> 223\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mruntime_environment\u001b[39m\u001b[39m\"\u001b[39m: _get_runtime_environment(),\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpython_version\u001b[39m\u001b[39m\"\u001b[39m: platform\u001b[39m.\u001b[39mpython_version(),\n\u001b[0;32m    225\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnannyml_version\u001b[39m\u001b[39m\"\u001b[39m: __version__,\n\u001b[0;32m    226\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:230\u001b[0m, in \u001b[0;36m_get_runtime_environment\u001b[1;34m()\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_runtime_environment\u001b[39m():\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mif\u001b[39;00m _is_running_in_docker():\n\u001b[0;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdocker\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:243\u001b[0m, in \u001b[0;36m_is_running_in_docker\u001b[1;34m()\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdocker\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m line \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m Path(\u001b[39m'\u001b[39;49m\u001b[39m/proc/self/cgroup\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mopen()):\n\u001b[0;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\pathlib.py:1252\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[39mOpen the file pointed by this path and return a file object, as\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39mthe built-in open() function does.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m, mode, buffering, encoding, errors, newline,\n\u001b[0;32m   1253\u001b[0m                opener\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener)\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\pathlib.py:1120\u001b[0m, in \u001b[0;36mPath._opener\u001b[1;34m(self, name, flags, mode)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_opener\u001b[39m(\u001b[39mself\u001b[39m, name, flags, mode\u001b[39m=\u001b[39m\u001b[39m0o666\u001b[39m):\n\u001b[0;32m   1119\u001b[0m     \u001b[39m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m, flags, mode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\proc\\\\self\\\\cgroup'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:496\u001b[0m, in \u001b[0;36mAbstractEstimator.fit\u001b[1;34m(self, reference_data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     reference_data \u001b[39m=\u001b[39m reference_data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(reference_data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    497\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidArgumentsException:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:211\u001b[0m, in \u001b[0;36mlog_usage.<locals>.logging_decorator.<locals>.logging_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m runtime_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m runtime_exception\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\usage_logging.py:160\u001b[0m, in \u001b[0;36mlog_usage.<locals>.logging_decorator.<locals>.logging_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[39m# run original function\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\performance_estimation\\direct_loss_estimation\\dle.py:281\u001b[0m, in \u001b[0;36mDLE._fit\u001b[1;34m(self, reference_data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidArgumentsException(\u001b[39m'\u001b[39m\u001b[39mdata contains no rows. Please provide a valid data set.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 281\u001b[0m _list_missing([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_true, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_pred], \u001b[39mlist\u001b[39;49m(reference_data\u001b[39m.\u001b[39;49mcolumns))\n\u001b[0;32m    283\u001b[0m _, categorical_feature_columns \u001b[39m=\u001b[39m _split_features_by_type(reference_data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_column_names)\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:568\u001b[0m, in \u001b[0;36m_list_missing\u001b[1;34m(columns_to_find, dataset_columns)\u001b[0m\n\u001b[0;32m    566\u001b[0m     dataset_columns \u001b[39m=\u001b[39m dataset_columns\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m--> 568\u001b[0m missing \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_to_find \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m dataset_columns]\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m missing:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:568\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m     dataset_columns \u001b[39m=\u001b[39m dataset_columns\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m--> 568\u001b[0m missing \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_to_find \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m dataset_columns]\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m missing:\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCalculatorException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m check_data_drift(reference, analysis, parameters)\n",
      "Cell \u001b[1;32mIn[69], line 46\u001b[0m, in \u001b[0;36mcheck_data_drift\u001b[1;34m(reference, analysis, parameters)\u001b[0m\n\u001b[0;32m     35\u001b[0m calculate_drift_multivariat(reference, \n\u001b[0;32m     36\u001b[0m                              analysis, \n\u001b[0;32m     37\u001b[0m                              feature_column_names\u001b[39m=\u001b[39mfeature_columns,\n\u001b[0;32m     38\u001b[0m                              timestamp_column_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m calculate_drift_univariate(reference, \n\u001b[0;32m     41\u001b[0m                             analysis, \n\u001b[0;32m     42\u001b[0m                             column_names\u001b[39m=\u001b[39mfeature_columns, \n\u001b[0;32m     43\u001b[0m                             treat_as_categorical\u001b[39m=\u001b[39m[], \n\u001b[0;32m     44\u001b[0m                             timestamp_column_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m estimate_performance(reference,\n\u001b[0;32m     47\u001b[0m                     analysis,\n\u001b[0;32m     48\u001b[0m                     feature_column_names\u001b[39m=\u001b[39;49mfeature_columns,\n\u001b[0;32m     49\u001b[0m                     y_pred\u001b[39m=\u001b[39;49mreference[\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     50\u001b[0m                     y_true\u001b[39m=\u001b[39;49mreference[\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     51\u001b[0m                     timestamp_column_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     52\u001b[0m                     \u001b[39m# metrics=['rmse', 'rmsle'],\u001b[39;00m\n\u001b[0;32m     53\u001b[0m                     \u001b[39m# tune_hyperparameters=False)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m create_psi_plot(feature_columns, reference, analysis)\n",
      "Cell \u001b[1;32mIn[69], line 151\u001b[0m, in \u001b[0;36mestimate_performance\u001b[1;34m(reference, analysis, feature_column_names, y_pred, y_true, timestamp_column_name, metrics)\u001b[0m\n\u001b[0;32m    141\u001b[0m os\u001b[39m.\u001b[39mmakedirs(folder_path, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    143\u001b[0m estimator \u001b[39m=\u001b[39m nml\u001b[39m.\u001b[39mDLE(feature_column_names\u001b[39m=\u001b[39mfeature_column_names,\n\u001b[0;32m    144\u001b[0m                     y_pred\u001b[39m=\u001b[39my_pred,\n\u001b[0;32m    145\u001b[0m                     y_true\u001b[39m=\u001b[39my_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m                     \u001b[39m# tune_hyperparameters=tune_hyperparameters\u001b[39;00m\n\u001b[0;32m    149\u001b[0m                     )\n\u001b[1;32m--> 151\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(reference)\n\u001b[0;32m    152\u001b[0m results \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mestimate(analysis)\n\u001b[0;32m    154\u001b[0m analysis_results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mfilter(period\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39manalysis\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto_df()\n",
      "File \u001b[1;32mc:\\Users\\jkick\\.conda\\envs\\housepricing\\lib\\site-packages\\nannyml\\base.py:502\u001b[0m, in \u001b[0;36mAbstractEstimator.fit\u001b[1;34m(self, reference_data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mraise\u001b[39;00m CalculatorException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed while fitting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mCalculatorException\u001b[0m: failed while fitting DLE[tune_hyperparameters=False, metrics=['MSE']].\nThe truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "check_data_drift(reference, analysis, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housepricing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
